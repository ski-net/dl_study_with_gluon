{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### REFERENCE\n",
    "\n",
    "* [Introduction to Recommender systems](http://gluon.mxnet.io/chapter11_recommender-systems/intro-recommender-systems.html)\n",
    "* [Matrix Factorization](http://mxnet.incubator.apache.org/tutorials/python/matrix_factorization.html)\n",
    "* [Deep Matrix Factorization using Apache MXNet](https://github.com/jmschrei/notebooks/blob/master/MXNet%20Deep%20Matrix%20Factorization/MxNet_Deep_Matrix_Factorization.ipynb)\n",
    "* [Movie Lens Dataset](https://grouplens.org/datasets/movielens/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## SET LIBRARY\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd, gluon\n",
    "#from mxnet.gluon.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "mx.random.seed(1071)\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## SET GLOBAL\n",
    "ctx = mx.cpu(0)\n",
    "gtx = mx.gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## SET WORK DIRETORY\n",
    "work_path = '/Users/boO/data8/boo/data.student/60.feat_study'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## SET PARAMS\n",
    "idx_tot = 35000\n",
    "idx_trn = 25000 \n",
    "\n",
    "epochs = 30\n",
    "btch_size = 16\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35000,)\n"
     ]
    }
   ],
   "source": [
    "## LOAD DATA\n",
    "tab = np.random.randn(250, 250)\n",
    "wv_i = np.random.randint(250, size=idx_tot)\n",
    "wv_j = np.random.randint(250, size=idx_tot)\n",
    "wv_v = tab[wv_i, wv_j]\n",
    "print(wv_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD0CAYAAACPUQ0CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2CWpGINdkor5f0AxeMlKZJ/9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b9106d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(wv_v, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xy_train = gluon.data.ArrayDataset(wv_i[:idx_trn], wv_j[:idx_trn], wv_v[:idx_trn].astype(np.float32))\n",
    "xy_train = gluon.data.DataLoader(xy_train, batch_size=btch_size, shuffle=True)\n",
    "xy_valid = gluon.data.ArrayDataset(wv_i[idx_trn:], wv_j[idx_trn:], wv_v[idx_trn:].astype(np.float32))\n",
    "xy_valid = gluon.data.DataLoader(xy_valid, batch_size=btch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[131 160 173  81   5  39 205  34 165  99   2 215 208 235 233  81]\n",
      "<NDArray 16 @cpu(0)>\n",
      "\n",
      "[ 11  50  60 149  85   5  54 243 192  59  53 112 124 101 217  83]\n",
      "<NDArray 16 @cpu(0)>\n",
      "\n",
      "[-1.05629039 -0.29805148  0.94929832  1.2885704  -0.39073372  1.18297327\n",
      "  0.94467235  0.7737698   1.76111472  0.49847716  0.88584882  0.29817027\n",
      "  0.89570659 -0.13142024  0.28553584  2.23126626]\n",
      "<NDArray 16 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "for user, item, scor in xy_valid:\n",
    "    user = user.as_in_context(ctx)\n",
    "    item = item.as_in_context(ctx)\n",
    "    scor = scor.as_in_context(ctx)\n",
    "    break\n",
    "print(user)\n",
    "print(item)\n",
    "print(scor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPH(\n",
      "  (user): Embedding(250 -> 32, float32)\n",
      "  (item): Embedding(250 -> 32, float32)\n",
      "  (dense): Dense(None -> 1, linear)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GPH(gluon.HybridBlock):\n",
    "    def __init__(self, vocab_size, embd_dim, num_output, **kwargs):\n",
    "        super(GPH, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.user = gluon.nn.Embedding(vocab_size, embd_dim)\n",
    "            self.item = gluon.nn.Embedding(vocab_size, embd_dim)\n",
    "            self.dense = gluon.nn.Dense(num_output)\n",
    "\n",
    "    def hybrid_forward(self, F, usr, itm):\n",
    "        # user latent features\n",
    "        usr = self.user(usr)\n",
    "        # item latent features\n",
    "        itm = self.item(itm)\n",
    "        # https://www.oreilly.com/ideas/deep-matrix-factorization-using-apache-mxnet\n",
    "        # Define the dot product between the two variables, which is the elementwise multiplication and a sum\n",
    "        #F.dot(usr, itm, transpose_b=True) #F.sum(F.dot(usr, itm, transpose_b=True), axis=1)\n",
    "        pred = F.sum(F.multiply(usr, itm), axis=1) \n",
    "        pred = self.dense(pred)\n",
    "        pred = F.reshape(pred,-1)\n",
    "        return pred\n",
    "    \n",
    "gph = GPH(vocab_size=250, embd_dim=32, num_output=1)\n",
    "gph.collect_params().initialize(mx.init.Xavier(), ctx=ctx)\n",
    "print(gph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPH(\n",
      "  (user): Embedding(250 -> 32, float32)\n",
      "  (item): Embedding(250 -> 32, float32)\n",
      "  (dense): Dense(None -> 16, Activation(relu))\n",
      "  (dropout): Dropout(p = 0.5)\n",
      "  (flatten): Flatten\n",
      "  (output): Dense(None -> 1, linear)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GPH(gluon.HybridBlock):\n",
    "    def __init__(self, vocab_size, embd_dim, num_hidden, num_output, **kwargs):\n",
    "        super(GPH, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.user = gluon.nn.Embedding(vocab_size, embd_dim)\n",
    "            self.item = gluon.nn.Embedding(vocab_size, embd_dim)\n",
    "            self.dense = gluon.nn.Dense(num_hidden, activation='relu')\n",
    "            self.dropout = gluon.nn.Dropout(0.5)\n",
    "            self.flatten = gluon.nn.Flatten()\n",
    "            self.output = gluon.nn.Dense(num_output)\n",
    "            \n",
    "    def hybrid_forward(self, F, usr, itm):\n",
    "        # user latent features\n",
    "        usr = self.user(usr)\n",
    "        # item latent features\n",
    "        itm = self.item(itm)\n",
    "        # https://www.oreilly.com/ideas/deep-matrix-factorization-using-apache-mxnet\n",
    "        # nn = mx.symbol.concat(user, movie)\n",
    "        # dim (int, optional, default='1') â€“ the dimension to be concated.\n",
    "        pred = F.concat(usr,itm,dim=1)\n",
    "        pred = self.flatten(pred)\n",
    "        pred = self.dense(pred)\n",
    "        pred = self.output(pred)\n",
    "        return pred\n",
    "    \n",
    "gph = GPH(vocab_size=250, embd_dim=32, num_hidden=16, num_output=1)\n",
    "gph.collect_params().initialize(mx.init.Xavier(), ctx=ctx)\n",
    "print(gph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16,)\n",
      "(16,)\n",
      "(16,)\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "## SANDBOX\n",
    "for i, (user, item, scor) in enumerate(xy_valid):\n",
    "    user = user.as_in_context(ctx)\n",
    "    item = item.as_in_context(ctx)\n",
    "    scor = scor.as_in_context(ctx)\n",
    "    break\n",
    "print(user.shape)\n",
    "print(item.shape)\n",
    "print(scor.shape)\n",
    "pred = gph(user, item)\n",
    "print(pred.shape)\n",
    "#print(l2loss(pred, scor))\n",
    "#rmse = mx.metric.RMSE()\n",
    "#rmse.update(preds=pred, labels=scor)\n",
    "#print(rmse.get()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2loss = gluon.loss.L2Loss()\n",
    "optimizer = gluon.Trainer(gph.collect_params(), 'sgd', {'learning_rate': learning_rate, 'wd': 0.001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluator(data_iterator, gph, loss_func):\n",
    "    rmse = mx.metric.RMSE()\n",
    "    loss_avg = 0.\n",
    "    for i, (user, item, scor) in enumerate(data_iterator):\n",
    "        user = user.as_in_context(ctx)\n",
    "        item = item.as_in_context(ctx)\n",
    "        scor = scor.as_in_context(ctx)\n",
    "        \n",
    "        pred = gph(user, item)\n",
    "        loss = loss_func(pred, scor)\n",
    "        rmse.update(preds=pred, labels=scor)\n",
    "        loss_avg = loss_avg*i/(i+1) + nd.mean(loss).asscalar()/(i+1)\n",
    "    return rmse.get()[1], loss_avg\n",
    "\n",
    "def plot_mets(loss_tr, loss_ts, rmse_tr, rmse_ts):\n",
    "    xs = list(range(len(loss_tr)))\n",
    "\n",
    "    f = plt.figure(figsize=(12,6))\n",
    "    fg1 = f.add_subplot(121)\n",
    "    fg2 = f.add_subplot(122)\n",
    "\n",
    "    fg1.set_xlabel('epoch',fontsize=14)\n",
    "    fg1.set_title('Comparing loss functions')\n",
    "    fg1.semilogy(xs, loss_tr)\n",
    "    fg1.semilogy(xs, loss_ts)\n",
    "    fg1.grid(True,which=\"both\")\n",
    "\n",
    "    fg1.legend(['training loss', 'testing loss'],fontsize=14)\n",
    "\n",
    "    fg2.set_title('Comparing accuracy')\n",
    "    fg1.set_xlabel('epoch',fontsize=14)\n",
    "    fg2.plot(xs, rmse_tr)\n",
    "    fg2.plot(xs, rmse_ts)\n",
    "    fg2.grid(True,which=\"both\")\n",
    "    fg2.legend(['training RMSE', 'testing RMSE'],fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0th epoch] Loss :  0.4971\n",
      "[0th epoch] Train RMSE :  0.8009, Valid  RMSE :  0.7924\n",
      "[1th epoch] Loss :  0.5048\n",
      "[1th epoch] Train RMSE :  0.8004, Valid  RMSE :  0.7922\n",
      "[2th epoch] Loss :  0.4891\n",
      "[2th epoch] Train RMSE :  0.8000, Valid  RMSE :  0.7917\n",
      "[3th epoch] Loss :  0.4961\n",
      "[3th epoch] Train RMSE :  0.7997, Valid  RMSE :  0.7918\n",
      "[4th epoch] Loss :  0.5183\n",
      "[4th epoch] Train RMSE :  0.7995, Valid  RMSE :  0.7916\n",
      "[5th epoch] Loss :  0.4984\n",
      "[5th epoch] Train RMSE :  0.7993, Valid  RMSE :  0.7914\n",
      "[6th epoch] Loss :  0.4980\n",
      "[6th epoch] Train RMSE :  0.7991, Valid  RMSE :  0.7912\n",
      "[7th epoch] Loss :  0.4887\n",
      "[7th epoch] Train RMSE :  0.7989, Valid  RMSE :  0.7912\n",
      "[8th epoch] Loss :  0.5033\n",
      "[8th epoch] Train RMSE :  0.7988, Valid  RMSE :  0.7912\n",
      "[9th epoch] Loss :  0.5214\n",
      "[9th epoch] Train RMSE :  0.7986, Valid  RMSE :  0.7912\n",
      "[10th epoch] Loss :  0.5017\n",
      "[10th epoch] Train RMSE :  0.7985, Valid  RMSE :  0.7910\n",
      "[11th epoch] Loss :  0.4974\n",
      "[11th epoch] Train RMSE :  0.7983, Valid  RMSE :  0.7910\n",
      "[12th epoch] Loss :  0.4911\n",
      "[12th epoch] Train RMSE :  0.7981, Valid  RMSE :  0.7909\n",
      "[13th epoch] Loss :  0.5124\n",
      "[13th epoch] Train RMSE :  0.7981, Valid  RMSE :  0.7909\n",
      "[14th epoch] Loss :  0.4862\n",
      "[14th epoch] Train RMSE :  0.7979, Valid  RMSE :  0.7910\n"
     ]
    }
   ],
   "source": [
    "idx_mets = pd.DataFrame({'loss_tr':[],'loss_ts':[],'rmse_tr':[],'rmse_ts':[]})\n",
    "n_iter = 0\n",
    "for epoch in range(epochs):\n",
    "    mov_loss = 0\n",
    "    for i, (user, item, scor) in enumerate(xy_train):\n",
    "        user = user.as_in_context(ctx)\n",
    "        item = item.as_in_context(ctx)\n",
    "        scor = scor.as_in_context(ctx)\n",
    "        \n",
    "        with autograd.record(train_mode=True):\n",
    "            pred = gph(user, item)\n",
    "            loss = l2loss(pred, scor)\n",
    "        loss.backward()\n",
    "        optimizer.step(btch_size)\n",
    "        n_iter +=1\n",
    "        mov_loss = .99 * mov_loss + .01 * nd.mean(loss).asscalar()\n",
    "        est_loss = mov_loss/(1-0.99**n_iter)\n",
    "        \n",
    "    print(\"[%sth epoch] Loss :  %0.4f\" % (epoch, est_loss))\n",
    "    rmse_train, loss_train = evaluator(xy_train, gph, l2loss)\n",
    "    rmse_valid, loss_valid = evaluator(xy_valid, gph, l2loss)\n",
    "    print(\"[%sth epoch] Train RMSE :  %0.4f, Valid  RMSE :  %0.4f\" % (epoch, rmse_train, rmse_valid))\n",
    "    idx_mets = pd.concat([idx_mets,pd.DataFrame({'loss_tr':[loss_train],'loss_ts':[loss_valid],'rmse_tr':[rmse_train],'rmse_ts':[rmse_valid]})],axis=0,ignore_index=True)\n",
    "    \n",
    "plot_mets(idx_mets['loss_tr'],idx_mets['loss_ts'],idx_mets['rmse_tr'],idx_mets['rmse_ts'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
